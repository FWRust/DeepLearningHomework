{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d63b1e9-198b-460d-bc06-d77eb64c3cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import mse, log_epoch\n",
    "\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "def start_train(dataset, in_features=1,lr = 0.1,batch_size = 32, optimizer = 'sgd'):\n",
    "    start_time = time.time()\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "#    print(f'Размер датасета: {len(dataset)}')\n",
    "#    print(f'Количество батчей: {len(dataloader)}')\n",
    "\n",
    "    # Создаём модель, функцию потерь и оптимизатор\n",
    "    model = LinearRegression(in_features)\n",
    "    criterion = nn.MSELoss()\n",
    "    if optimizer == 'sgd':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    elif optimizer == 'adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=lr)\n",
    "    else:\n",
    "        raise ValueError('Неизвестный оптимизатор')\n",
    "    # Параметры регуляризации\n",
    "    l_lambda = 0.01  # коэффициент для регуляризации\n",
    "    regularization = 'l2'  # тип регуляризации l1, l2 или None\n",
    "\n",
    "    # Параметры early stopping\n",
    "    patience = 5  # количество эпох без улучшения перед остановкой\n",
    "    best_loss = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    # Обучаем модель\n",
    "    epochs = 100\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        total_loss = 0\n",
    "\n",
    "        for i, (batch_X, batch_y) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(batch_X)\n",
    "\n",
    "            # Основная функция потерь\n",
    "            y_pred = y_pred.squeeze()\n",
    "            loss = criterion(y_pred, batch_y)\n",
    "\n",
    "            # L2\n",
    "            if regularization == 'l2':\n",
    "                l2_reg = torch.tensor(0.)\n",
    "                for param in model.parameters():\n",
    "                    l2_reg += torch.norm(param, p=2) ** 2\n",
    "                loss += l_lambda * l2_reg\n",
    "            # L1\n",
    "            elif regularization == 'l1':\n",
    "                l1_reg = torch.tensor(0.)\n",
    "                for param in model.parameters():\n",
    "                    l1_reg += torch.norm(param, p=1)\n",
    "                loss += l_lambda * l1_reg\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / (i + 1)\n",
    "\n",
    "        # Early stopping\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            epochs_without_improvement = 0\n",
    "            # Сохраняем лучшую модель\n",
    "            torch.save(model.state_dict(), 'models/best_linreg_torch.pth')\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement >= patience:\n",
    "#                print(f'Early stopping на эпохе {epoch}')\n",
    "                return time.time() - start_time, avg_loss, epoch\n",
    "\n",
    "#        if epoch % 10 == 0:\n",
    "#            log_epoch(epoch, avg_loss)\n",
    "    return time.time() - start_time, avg_loss, None\n",
    "\n",
    "def evaluate():\n",
    "    best_model = LinearRegression(in_features=1)\n",
    "    best_model.load_state_dict(torch.load('models/best_linreg_torch.pth'))\n",
    "    best_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ab3b746-bc7d-48a7-a3ac-dec4fb8d7cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, file_path, numeric_cols=None, categorical_cols=None, binary_cols=None, target_col=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            file_path (str): Путь к CSV файлу\n",
    "            numeric_cols (list): Список числовых колонок\n",
    "            categorical_cols (list): Список категориальных колонок\n",
    "            binary_cols (list): Список бинарных колонок\n",
    "            target_col (str): Искомое\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(file_path)\n",
    "        self.numeric_cols = numeric_cols if numeric_cols else []\n",
    "        self.categorical_cols = categorical_cols if categorical_cols else []\n",
    "        self.binary_cols = binary_cols if binary_cols else []\n",
    "        self.target_col = target_col\n",
    "\n",
    "        self.preprocess_data()\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        # Нормализация числовых данных (MinMax)\n",
    "        for col in self.numeric_cols:\n",
    "            col_data = torch.tensor(self.data[col].values, dtype=torch.float32)\n",
    "            min_val = torch.min(torch.tensor(col_data))\n",
    "            max_val = torch.max(torch.tensor(col_data))\n",
    "            self.data[col] = ((col_data - min_val) / (max_val - min_val)) - 1\n",
    "\n",
    "        # Кодирование категориальных данных (One-Hot), громоздкое но универсальное\n",
    "        for col in self.categorical_cols:\n",
    "            unique_values = self.data[col].unique()\n",
    "            mapping = {v: i for i, v in enumerate(unique_values)}\n",
    "            self.data[col] = self.data[col].map(mapping)\n",
    "            # Конвертируем в one-hot\n",
    "            one_hot = torch.zeros((len(self.data), len(unique_values)))\n",
    "            one_hot[torch.arange(len(self.data)), self.data[col].values] = 1\n",
    "            # Удаляем оригинальную колонку и добавляем one-hot колонки\n",
    "            self.data.drop(col, axis=1, inplace=True)\n",
    "            for i, val in enumerate(unique_values):\n",
    "                self.data[f\"{col}_{val}\"] = one_hot[:, i]\n",
    "\n",
    "        # Кодирование бинарных данных\n",
    "        for col in self.binary_cols:\n",
    "            unique_values = self.data[col].unique()\n",
    "            mapping = {v: i for i, v in enumerate(unique_values)}\n",
    "            self.data[col] = self.data[col].map(mapping)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = []\n",
    "\n",
    "        # Собираем все признаки и объеденяем в один тензор с которым сможет работать Pytorch\n",
    "        for col in self.numeric_cols:\n",
    "            features.append(torch.tensor(self.data.iloc[idx][col], dtype=torch.float32))\n",
    "\n",
    "        for col in self.binary_cols:\n",
    "            features.append(torch.tensor(self.data.iloc[idx][col], dtype=torch.float32))\n",
    "\n",
    "        for col in self.categorical_cols:\n",
    "            for c in self.data.columns:\n",
    "                if c.startswith(f\"{col}_\"):\n",
    "                    features.append(torch.tensor(self.data.iloc[idx][c], dtype=torch.float32))\n",
    "\n",
    "        features = torch.stack(features)\n",
    "\n",
    "        if self.target_col:\n",
    "            target = torch.tensor(self.data.iloc[idx][self.target_col], dtype=torch.float32)\n",
    "            return features, target\n",
    "\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c14fa4d-2073-4f51-8058-62f73f7301f1",
   "metadata": {},
   "source": [
    "Немного изменил код чтобы он выводил только информацию релевантную для анализа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9129e32b-0f76-49e8-9b32-a50159db9706",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MobS\\AppData\\Local\\Temp\\ipykernel_9112\\1720545623.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  min_val = torch.min(torch.tensor(col_data))\n",
      "C:\\Users\\MobS\\AppData\\Local\\Temp\\ipykernel_9112\\1720545623.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_val = torch.max(torch.tensor(col_data))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr | batch_size | optimizer | time |    loss    | early stop epoch\n",
      "0.01 |    16    |   sgd   | 0.427 | 228867864.0 | 30\n",
      "0.01 |    16    |   adam   | 0.089 | 1856745024.0 | 7\n",
      "0.01 |    16    |   rmsprop   | 0.129 | 1621315136.0 | 10\n",
      "0.01 |    32    |   sgd   | 1.167 | 177250256.0 | None\n",
      "0.01 |    32    |   adam   | 1.193 | 1726917632.0 | None\n",
      "0.01 |    32    |   rmsprop   | 1.202 | 1726622080.0 | None\n",
      "0.01 |    64    |   sgd   | 1.187 | 177250384.0 | None\n",
      "0.01 |    64    |   adam   | 1.207 | 1726946560.0 | None\n",
      "0.01 |    64    |   rmsprop   | 1.194 | 1726700544.0 | None\n",
      "0.1 |    16    |   sgd   | 0.322 | 81993108.0 | 25\n",
      "0.1 |    16    |   adam   | 0.073 | 1758329024.0 | 6\n",
      "0.1 |    16    |   rmsprop   | 0.071 | 1784133632.0 | 6\n",
      "0.1 |    32    |   sgd   | 1.219 | 58795376.0 | None\n",
      "0.1 |    32    |   adam   | 1.198 | 1725270784.0 | None\n",
      "0.1 |    32    |   rmsprop   | 1.283 | 1723519232.0 | None\n",
      "0.1 |    64    |   sgd   | 1.219 | 58795572.0 | None\n",
      "0.1 |    64    |   adam   | 1.225 | 1725330176.0 | None\n",
      "0.1 |    64    |   rmsprop   | 1.251 | 1723491328.0 | None\n",
      "0.2 |    16    |   sgd   | 0.259 | 79602168.0 | 20\n",
      "0.2 |    16    |   adam   | 0.088 | 1682312512.0 | 7\n",
      "0.2 |    16    |   rmsprop   | 0.118 | 1658848896.0 | 9\n",
      "0.2 |    32    |   sgd   | 1.159 | 46341688.0 | None\n",
      "0.2 |    32    |   adam   | 1.221 | 1723631616.0 | None\n",
      "0.2 |    32    |   rmsprop   | 1.247 | 1720158976.0 | None\n",
      "0.2 |    64    |   sgd   | 1.201 | 46341712.0 | None\n",
      "0.2 |    64    |   adam   | 1.238 | 1723603968.0 | None\n",
      "0.2 |    64    |   rmsprop   | 1.239 | 1720100608.0 | None\n"
     ]
    }
   ],
   "source": [
    "# 3.1\n",
    "dataset = CSVDataset(\"data/Multiple.csv\", numeric_cols = [\"age\",\"experience\"], target_col = \"income\")\n",
    "print('lr | batch_size | optimizer | time |    loss    | early stop epoch')\n",
    "for lr in [0.01,0.1,0.2]:\n",
    "    for batch_size in [16,32,64]:\n",
    "        for optimizer in ['sgd','adam','rmsprop']:\n",
    "            res = start_train(dataset,2,lr=lr,batch_size=batch_size,optimizer=optimizer)\n",
    "            print(lr,'|   ',batch_size,'   |  ', optimizer,'  |',round(res[0],3),'|',res[1],'|',res[2])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afad8cd-b843-4d61-9469-020c3b565cc7",
   "metadata": {},
   "source": [
    "Важный вывод - с малыми батчами отлично работают adam и rmsprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d050cddd-94cf-4e45-853d-1a019144405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.2\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, file_path, numeric_cols=None, categorical_cols=None, binary_cols=None, target_col=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            file_path (str): Путь к CSV файлу\n",
    "            numeric_cols (list): Список числовых колонок\n",
    "            categorical_cols (list): Список категориальных колонок\n",
    "            binary_cols (list): Список бинарных колонок\n",
    "            target_col (str): Искомое\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(file_path)\n",
    "        self.numeric_cols = numeric_cols if numeric_cols else []\n",
    "        self.categorical_cols = categorical_cols if categorical_cols else []\n",
    "        self.binary_cols = binary_cols if binary_cols else []\n",
    "        self.target_col = target_col\n",
    "\n",
    "        self.preprocess_data()\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        # Нормализация числовых данных (MinMax)\n",
    "        for col in self.numeric_cols:\n",
    "            col_data = torch.tensor(self.data[col].values, dtype=torch.float32)\n",
    "            min_val = torch.min(torch.tensor(col_data))\n",
    "            max_val = torch.max(torch.tensor(col_data))\n",
    "            self.data[col] = ((col_data - min_val) / (max_val - min_val)) - 1\n",
    "\n",
    "        numeric_data = self.data[self.numeric_cols].values # ! добавим в датасет новый признак с средним арифметическим всех остальных\n",
    "        mean_feature = torch.mean(torch.tensor(numeric_data, dtype=torch.float32), dim=1)\n",
    "        self.data['mean_feature'] = mean_feature\n",
    "        self.numeric_cols.append('mean_feature')\n",
    "        \n",
    "        squared_feature = torch.pow(torch.tensor(self.data[self.numeric_cols[0]].values, dtype=torch.float32), 2) # ! новый признак - первый численный признак в квадрате\n",
    "        self.data['squared_feature'] = squared_feature\n",
    "        self.numeric_cols.append('squared_feature')\n",
    "\n",
    "        product_feature = (torch.tensor(self.data[self.numeric_cols[0]].values, dtype=torch.float32) * \n",
    "                             torch.tensor(self.data[self.numeric_cols[1]].values, dtype=torch.float32)) # ! новый признак - произведение двух численных признаков\n",
    "        self.data['product_feature'] = product_feature\n",
    "        self.numeric_cols.append('product_feature')\n",
    "\n",
    "\n",
    "        # Кодирование категориальных данных (One-Hot), громоздкое но универсальное\n",
    "        for col in self.categorical_cols:\n",
    "            unique_values = self.data[col].unique()\n",
    "            mapping = {v: i for i, v in enumerate(unique_values)}\n",
    "            self.data[col] = self.data[col].map(mapping)\n",
    "            # Конвертируем в one-hot\n",
    "            one_hot = torch.zeros((len(self.data), len(unique_values)))\n",
    "            one_hot[torch.arange(len(self.data)), self.data[col].values] = 1\n",
    "            # Удаляем оригинальную колонку и добавляем one-hot колонки\n",
    "            self.data.drop(col, axis=1, inplace=True)\n",
    "            for i, val in enumerate(unique_values):\n",
    "                self.data[f\"{col}_{val}\"] = one_hot[:, i]\n",
    "\n",
    "        # Кодирование бинарных данных\n",
    "        for col in self.binary_cols:\n",
    "            unique_values = self.data[col].unique()\n",
    "            mapping = {v: i for i, v in enumerate(unique_values)}\n",
    "            self.data[col] = self.data[col].map(mapping)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = []\n",
    "\n",
    "        # Собираем все признаки и объеденяем в один тензор с которым сможет работать Pytorch\n",
    "        for col in self.numeric_cols:\n",
    "            features.append(torch.tensor(self.data.iloc[idx][col], dtype=torch.float32))\n",
    "\n",
    "        for col in self.binary_cols:\n",
    "            features.append(torch.tensor(self.data.iloc[idx][col], dtype=torch.float32))\n",
    "\n",
    "        for col in self.categorical_cols:\n",
    "            for c in self.data.columns:\n",
    "                if c.startswith(f\"{col}_\"):\n",
    "                    features.append(torch.tensor(self.data.iloc[idx][c], dtype=torch.float32))\n",
    "\n",
    "        features = torch.stack(features)\n",
    "\n",
    "        if self.target_col:\n",
    "            target = torch.tensor(self.data.iloc[idx][self.target_col], dtype=torch.float32)\n",
    "            return features, target\n",
    "\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ce36aa-9230-4c05-a717-b21d331fde3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Добавил три признака в датасет, среднее арифметическое, квадрат первого, и произведение двух."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4f6f1e9-bed6-4fff-8ab2-3363591e0de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MobS\\AppData\\Local\\Temp\\ipykernel_9112\\723393383.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  min_val = torch.min(torch.tensor(col_data))\n",
      "C:\\Users\\MobS\\AppData\\Local\\Temp\\ipykernel_9112\\723393383.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_val = torch.max(torch.tensor(col_data))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr | batch_size | optimizer | time |    loss    | early stop epoch\n",
      "0.1 |    32    |   sgd   | 2.181 | 54616688.0 | None\n"
     ]
    }
   ],
   "source": [
    "dataset = CSVDataset(\"data/Multiple.csv\", numeric_cols = [\"age\",\"experience\"], target_col = \"income\")\n",
    "print('lr | batch_size | optimizer | time |    loss    | early stop epoch')\n",
    "res = start_train(dataset,5)\n",
    "print('0.1','|   ',32,'   |  ', 'sgd','  |',round(res[0],3),'|',res[1],'|',res[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6fd97e-fbd0-4a6a-8144-c4330c289272",
   "metadata": {},
   "source": [
    "По итогу с добавлением новых признаков длительность обучения выросла, но также упал loss, значит существуют ситуации,\n",
    "где имеет смысл применять feature engineering."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
