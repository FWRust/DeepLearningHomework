{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d63b1e9-198b-460d-bc06-d77eb64c3cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Примечание: т.к. работаю в jupyter в ноутбуки приходится заново добавлять классы моделей и датасетов, насколько я знаю из ipynb импортировать \n",
    "#в другой нельзя, но также пользовался этим чтобы вносить небольшие правки например количество логируемой моделью информации в homework_experiment\n",
    "\n",
    "#1.1\n",
    "# Модифицируйте существующую линейную регрессию:\n",
    "# - Добавьте L1 и L2 регуляризацию\n",
    "# - Добавьте early stopping\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import mse, log_epoch\n",
    "\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "def start_train(dataset, in_features=1):\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    print(f'Размер датасета: {len(dataset)}')\n",
    "    print(f'Количество батчей: {len(dataloader)}')\n",
    "\n",
    "    # Создаём модель, функцию потерь и оптимизатор\n",
    "    model = LinearRegression(in_features)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "    # Параметры регуляризации\n",
    "    l_lambda = 0.01  # коэффициент для регуляризации\n",
    "    regularization = 'l2'  # тип регуляризации l1, l2 или None\n",
    "\n",
    "    # Параметры early stopping\n",
    "    patience = 5  # количество эпох без улучшения перед остановкой\n",
    "    best_loss = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    # Обучаем модель\n",
    "    epochs = 100\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        total_loss = 0\n",
    "\n",
    "        for i, (batch_X, batch_y) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(batch_X)\n",
    "\n",
    "            # Основная функция потерь\n",
    "            loss = criterion(y_pred, batch_y)\n",
    "\n",
    "            # L2\n",
    "            if regularization == 'l2':\n",
    "                l2_reg = torch.tensor(0.)\n",
    "                for param in model.parameters():\n",
    "                    l2_reg += torch.norm(param, p=2) ** 2\n",
    "                loss += l_lambda * l2_reg\n",
    "            # L1\n",
    "            elif regularization == 'l1':\n",
    "                l1_reg = torch.tensor(0.)\n",
    "                for param in model.parameters():\n",
    "                    l1_reg += torch.norm(param, p=1)\n",
    "                loss += l_lambda * l1_reg\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / (i + 1)\n",
    "\n",
    "        # Early stopping\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            epochs_without_improvement = 0\n",
    "            # Сохраняем лучшую модель\n",
    "            torch.save(model.state_dict(), 'models/best_linreg_torch.pth')\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement >= patience:\n",
    "                print(f'Early stopping на эпохе {epoch}')\n",
    "                break\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            log_epoch(epoch, avg_loss)\n",
    "\n",
    "def evaluate():\n",
    "    best_model = LinearRegression(in_features=1)\n",
    "    best_model.load_state_dict(torch.load('models/best_linreg_torch.pth'))\n",
    "    best_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11e16cc-ac2d-4e0f-955b-36b4cac37599",
   "metadata": {},
   "source": [
    "Добавил L1 и L2 регуляризацию по формулам с лекций, также early stopping с терпением по умолчанию = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afe709e-bbbb-4917-8214-6fc508b49e23",
   "metadata": {},
   "source": [
    "# 1.2\n",
    "# не догадался как самостоятельно реализовать многоклассовую классификацию, прошу прощения :("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
