# №1
Создал простой пайплайн из списка встроенных аугментаций, и создал датасет, затем взял по одной картинке из каждого класса, и пропустил каждый пример отдельно через каждый этап пайплайна, и весь пайплайн в целом.
Пример результата:
![1](https://github.com/FWRust/DeepLearningHomework/blob/main/5/pics/2.png)
# №2
В файл extra_augs.py добавил собственные аугментации: случайное размытие, случайная пикселизация, случайная яркость. Пропустил примеры из прошлого задания через пайплайн содержащий все три аугментации.
В итоге аугментации оказались существенно более "агрессивными" чем встроенные, они сильно слишком сильно изменяли изображение, особенно сильно работают вместе пикселизация с размытием, но если исопльзовать их по отдельности,
то они могут быть достаточно эффективны.
Пример:

![2](https://github.com/FWRust/DeepLearningHomework/blob/main/5/pics/1.png)
# №3
В utils.py добавил три функции: подсчет кол-ва изображений в каждом классе датасета, анализ размеров изображений в датасете, и визуализация результатов прошлых двух функций. Загрузил весь датасет и проверил на нем.
Результат:

![3](https://github.com/FWRust/DeepLearningHomework/blob/main/5/pics/4.png)
Как мы видим кол-во изображений по классам одинаково - это отлично, распределение размеров неравное, по неизвестной причине подавлюящее большинство изображений имеет ширину 564, распределение высоты более равномерное.

# №4
Создал собственный класс для пайплайна аугментаций и добавил его в файл utils.py, в класс добавил все необходимы функции: добавление/удаление аугментаций, вывод списка аугментаций и применение к изображению, затем создал конфиги разной силы, создал пайплайны с соотвествующими конфигами и пропустил через них весь датасет, результат сохранил в папку 5_augmented.
Ссылка на 5_augmented: https://drive.google.com/drive/folders/18cVto5l8ut9utXXM5dHwDGtztJUxJuWm?usp=sharing
# №5
В файл utils.py добавил функции измеряющие время и потребление памяти при загрузке и аугментации изображений разных размеров, а также визуализации этих данных, пропустил весь датасет(оригинальный) через них и получил следующие результаты:

РЕЗУЛЬТАТЫ ЭКСПЕРИМЕНТА

| Размер    | Время загрузки | Время аугментаций | Общее время | Память (MB) |
|-----------|----------------|-------------------|-------------|-------------|
| 64x64     | 0.608          | 0.095             | 0.703       | -0.8        |
| 128x128   | 0.679          | 0.163             | 0.841       | 2.6         |
| 224x224   | 0.760          | 0.246             | 1.006       | 58.3        |
| 512x512   | 1.030          | 0.938             | 1.968       | 468.6       |


![4](https://github.com/FWRust/DeepLearningHomework/blob/main/5/pics/4.png)

Заметно, что зависимость времени и памяти от размера примерно линейна, хотя при этом время и потребление памяти на загрузку зависит от размера изображения гораздо меньше, чем на аугментации.

# №6
Я использовал пример данный в дз, но модифицировал его, добавив разделение на тренировочный и валидационный датасет, а также проверку на val датасете после тренировки, также добавил визуализацию потерь и точности модели, дообучил модель на изображения полученных в 4 задании, в среднем модель начинает переобучатся на 3-4 эпохе, финальная точность - 78.7%
Графики:

![5](https://github.com/FWRust/DeepLearningHomework/blob/main/5/pics/5.png)
